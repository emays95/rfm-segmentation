{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90134ecd-0425-4248-b32f-0c059707f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350f7ed3-4797-4844-a48e-03f58863af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, pandas as ps\n",
    "from pyspark.sql import SparkSession, functions as sf, Window\n",
    "from pyspark.sql.functions import col, collect_list\n",
    "from pyspark.sql.types import *\n",
    "import psycopg2\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bf7037-b9fb-456d-98f0-956780e81bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.driver.memory\", \"8g\")\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local\")\\\n",
    "    .config(conf=conf)\\\n",
    "    .appName(\"ETL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cef40f1-e766-4282-a0be-49a0d0d9a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oltp_params = {\n",
    "    'user': 'admin',\n",
    "    'password': 'password',\n",
    "    \"driver\": \"org.postgresql_postgresql-42.7.3.jar\"\n",
    "}\n",
    "\n",
    "oltp_url = \"jdbc:postgresql://rfm-segmentation-oltp-db-1:5432/trans_oltp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e278916-1a00-4020-a041-6b12e10af858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector(spark://5ab2b1b817ac:43457/jars/org.checkerframework_checker-qual-3.42.0.jar, spark://5ab2b1b817ac:43457/jars/org.postgresql_postgresql-42.7.3.jar)\n"
     ]
    }
   ],
   "source": [
    "# print(spark_session.sparkContext._jvm.java.sql.DriverManager.getDrivers())\n",
    "print(spark_session.sparkContext._jsc.sc().listJars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e1d65c-6233-4ccc-b1b0-f2ebd3c1db2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+-------+\n",
      "|  trans_id|trans_date|          total_cost|payment_method|         city|       store_type|discount_applied|           promotion|cust_id|\n",
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+-------+\n",
      "|1000299020|2021-07-03|78.20000000000000...|Mobile Payment|        Miami| Department Store|           false|Discount on Selec...|  33877|\n",
      "|1000342674|2021-10-25|11.60000000000000...|Mobile Payment|San Francisco|      Supermarket|            true|BOGO (Buy One Get...|  33877|\n",
      "|1000806142|2020-05-25|90.06000000000000...|    Debit Card|      Chicago|   Warehouse Club|            true|                None| 629479|\n",
      "|1000008294|2020-07-27|90.77000000000000...|          Cash|San Francisco| Department Store|            true|BOGO (Buy One Get...| 143811|\n",
      "|1000641795|2020-05-22|68.82000000000000...|Mobile Payment|       Boston|  Specialty Store|            true|Discount on Selec...| 278700|\n",
      "|1000933527|2021-08-07|94.91000000000000...|          Cash|      Atlanta|   Warehouse Club|            true|                None| 598332|\n",
      "|1000604321|2022-11-05|84.95000000000000...|          Cash|      Chicago|Convenience Store|           false|BOGO (Buy One Get...|  83709|\n",
      "|1000337582|2022-07-21|28.46000000000000...|Mobile Payment|  Los Angeles|  Specialty Store|           false|Discount on Selec...| 142346|\n",
      "|1000556698|2021-10-14|18.47000000000000...|   Credit Card|      Seattle|Convenience Store|           false|Discount on Selec...| 142346|\n",
      "|1000699026|2023-08-11|88.97000000000000...|          Cash|      Chicago|      Supermarket|           false|                None| 142346|\n",
      "|1000720110|2024-04-15|80.04000000000000...|Mobile Payment|  Los Angeles|   Warehouse Club|           false|Discount on Selec...| 142346|\n",
      "|1000991622|2022-08-22|36.17000000000000...|Mobile Payment|      Atlanta|  Specialty Store|           false|                None| 142346|\n",
      "|1000739431|2023-04-21|11.81000000000000...|          Cash|San Francisco|   Warehouse Club|           false|                None| 264869|\n",
      "|1000437352|2020-03-17|33.21000000000000...|   Credit Card|      Seattle|  Specialty Store|            true|Discount on Selec...| 269538|\n",
      "|1000365148|2022-09-04|22.94000000000000...|          Cash|      Chicago|  Specialty Store|           false|                None| 390893|\n",
      "|1000329834|2020-09-09|93.11000000000000...|    Debit Card|      Chicago|         Pharmacy|            true|Discount on Selec...| 128000|\n",
      "|1000344630|2021-05-26|56.68000000000000...|          Cash|     New York|  Specialty Store|           false|BOGO (Buy One Get...|  85631|\n",
      "|1000886696|2022-09-08|36.49000000000000...|    Debit Card|      Seattle|      Supermarket|            true|                None| 610172|\n",
      "|1000890940|2020-04-29|78.67000000000000...|Mobile Payment|      Atlanta|         Pharmacy|           false|Discount on Selec...| 582400|\n",
      "|1000926569|2024-01-22|49.58000000000000...|Mobile Payment|        Miami|      Supermarket|           false|Discount on Selec...| 582400|\n",
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark_session.read.format('jdbc').option('url', oltp_url).option('dbtable', \"trans\").option('user', 'admin').option('password', 'password').option('driver', \"org.postgresql.Driver\").load()\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069aa035-f25e-4915-acb0-39124f5e4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dim = spark_session.read.format('jdbc').option('url', oltp_url).option('dbtable', \"product\").option('user', 'admin').option('password', 'password').option('driver', \"org.postgresql.Driver\").load()\n",
    "customer_dim = spark_session.read.format('jdbc').option('url', oltp_url).option('dbtable', \"cust\").option('user', 'admin').option('password', 'password').option('driver', \"org.postgresql.Driver\").load()\n",
    "tran_prod_fact = spark_session.read.format('jdbc').option('url', oltp_url).option('dbtable', \"trans_prod\").option('user', 'admin').option('password', 'password').option('driver', \"org.postgresql.Driver\").load()\n",
    "tran_dim = spark_session.read.format('jdbc').option('url', oltp_url).option('dbtable', \"trans\").option('user', 'admin').option('password', 'password').option('driver', \"org.postgresql.Driver\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edecd490-bf3b-4c16-b799-3ce5284d4e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, product: string, trans_id: string, product_id: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_prod_fact.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5721b40c-0001-4c41-9fe5-37bdd40bf681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, customer_name: string, customer_category: string, cust_id: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_dim.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6371df60-07f8-4948-881f-53f792a9389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, product: string, product_id: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dim.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e0d915c-20c7-4f14-9c01-63dd378e3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, trans_id: string, total_cost: string, payment_method: string, city: string, store_type: string, promotion: string, cust_id: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_dim.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21ff7408-1ffb-4b3a-9bbb-1b59f404cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-------+\n",
      "|  trans_id|product_id|trans_date|cust_id|\n",
      "+----------+----------+----------+-------+\n",
      "|1000001491|         2|2022-10-29| 315863|\n",
      "|1000010824|         2|2022-01-06| 423272|\n",
      "|1000025357|         2|2023-11-30| 189014|\n",
      "|1000027766|         1|2020-11-11| 398088|\n",
      "|1000028663|         1|2023-08-22| 513663|\n",
      "|1000032837|         1|2023-03-24| 333029|\n",
      "|1000036123|         1|2020-11-26|  27619|\n",
      "|1000038805|         1|2021-09-23| 378306|\n",
      "|1000040863|         2|2022-04-28| 434641|\n",
      "|1000043591|         1|2021-07-26|  65245|\n",
      "|1000050636|         2|2023-08-20|  38189|\n",
      "|1000050860|         2|2020-08-30|  30304|\n",
      "|1000055410|         1|2021-07-31|  89984|\n",
      "|1000055491|         1|2024-03-09| 431868|\n",
      "|1000059460|         1|2021-09-05| 318968|\n",
      "|1000060350|         1|2021-05-22| 228746|\n",
      "|1000062227|         2|2022-12-03|  98458|\n",
      "|1000074421|         1|2020-09-18|  54856|\n",
      "|1000091287|         2|2023-02-11| 107278|\n",
      "|1000099710|         2|2020-06-10| 245685|\n",
      "+----------+----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tran_prod_fact2 = tran_prod_fact.join(other=tran_dim, on='trans_id', how='left').select(['trans_id', 'product_id', 'trans_date', 'cust_id'])\n",
    "tran_prod_fact2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6224cf-7b12-4f72-9e27-41666b03c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+\n",
      "|  trans_id|trans_date|          total_cost|payment_method|         city|       store_type|discount_applied|           promotion|\n",
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+\n",
      "|1000299020|2021-07-03|78.20000000000000...|Mobile Payment|        Miami| Department Store|           false|Discount on Selec...|\n",
      "|1000342674|2021-10-25|11.60000000000000...|Mobile Payment|San Francisco|      Supermarket|            true|BOGO (Buy One Get...|\n",
      "|1000806142|2020-05-25|90.06000000000000...|    Debit Card|      Chicago|   Warehouse Club|            true|                None|\n",
      "|1000008294|2020-07-27|90.77000000000000...|          Cash|San Francisco| Department Store|            true|BOGO (Buy One Get...|\n",
      "|1000641795|2020-05-22|68.82000000000000...|Mobile Payment|       Boston|  Specialty Store|            true|Discount on Selec...|\n",
      "|1000933527|2021-08-07|94.91000000000000...|          Cash|      Atlanta|   Warehouse Club|            true|                None|\n",
      "|1000604321|2022-11-05|84.95000000000000...|          Cash|      Chicago|Convenience Store|           false|BOGO (Buy One Get...|\n",
      "|1000337582|2022-07-21|28.46000000000000...|Mobile Payment|  Los Angeles|  Specialty Store|           false|Discount on Selec...|\n",
      "|1000556698|2021-10-14|18.47000000000000...|   Credit Card|      Seattle|Convenience Store|           false|Discount on Selec...|\n",
      "|1000699026|2023-08-11|88.97000000000000...|          Cash|      Chicago|      Supermarket|           false|                None|\n",
      "|1000720110|2024-04-15|80.04000000000000...|Mobile Payment|  Los Angeles|   Warehouse Club|           false|Discount on Selec...|\n",
      "|1000991622|2022-08-22|36.17000000000000...|Mobile Payment|      Atlanta|  Specialty Store|           false|                None|\n",
      "|1000739431|2023-04-21|11.81000000000000...|          Cash|San Francisco|   Warehouse Club|           false|                None|\n",
      "|1000437352|2020-03-17|33.21000000000000...|   Credit Card|      Seattle|  Specialty Store|            true|Discount on Selec...|\n",
      "|1000365148|2022-09-04|22.94000000000000...|          Cash|      Chicago|  Specialty Store|           false|                None|\n",
      "+----------+----------+--------------------+--------------+-------------+-----------------+----------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tran_dim2= tran_dim.drop('cust_id')\n",
    "tran_dim2.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4b097c-48f8-40bb-ac8c-4d22152da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "olap_params = {\n",
    "    'host': 'rfm-segmentation-olap-db-1',\n",
    "    'database': 'trans_olap',\n",
    "    'user': 'admin',\n",
    "    'password': 'password',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66574711-9823-4e4b-a403-23bae01854d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_from_df(df, table, conn=psycopg2.connect(**olap_params)):\n",
    "    tmp = './tmp'\n",
    "    df.write.csv(tmp,mode='overwrite')\n",
    "    tmp_files = glob.glob('./tmp/*.csv')\n",
    "    print(tmp_files)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        for file in tmp_files:\n",
    "            with open(file, 'r') as f:\n",
    "                cursor.copy_from(f, table, sep=\",\", )\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as e:\n",
    "        [os.remove(file) for file in tmp_files]\n",
    "        print(\"Error: %s\" % e)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"Table %s copied from dataframe\" % table)\n",
    "    cursor.execute(F\"Select * FROM {table} LIMIT 5;\")\n",
    "    cursor.fetchall()\n",
    "    cursor.close()\n",
    "    [os.remove(file) for file in tmp_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64451346-1849-4303-89dd-6e68ca53f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tmp/part-00000-6aaba813-94f9-45bb-8f0c-153e8fb025d6-c000.csv']\n",
      "Error: relation \"trans_dim\" does not exist\n",
      "\n",
      "['./tmp/part-00000-bb1aa290-3e5f-4db7-b453-3f5ff796ea5c-c000.csv']\n",
      "Error: duplicate key value violates unique constraint \"cust_dim_pkey\"\n",
      "DETAIL:  Key (cust_id)=(David Melton) already exists.\n",
      "CONTEXT:  COPY cust_dim, line 151\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `prod_id` cannot be resolved. Did you mean one of the following? [`product`, `product_id`].;\n'Project ['prod_id, product#82]\n+- Relation [product#82,product_id#83] JDBCRelation(product) [numPartitions=1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m insert_from_df(df\u001b[38;5;241m=\u001b[39mtran_dim2, table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrans_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m insert_from_df(df\u001b[38;5;241m=\u001b[39mcustomer_dim, table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcust_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m insert_from_df(df\u001b[38;5;241m=\u001b[39m\u001b[43mproduct_dim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprod_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m insert_from_df(df\u001b[38;5;241m=\u001b[39mtran_prod_fact, table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrans_prod_fact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:3223\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3180\u001b[0m \n\u001b[1;32m   3181\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3223\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `prod_id` cannot be resolved. Did you mean one of the following? [`product`, `product_id`].;\n'Project ['prod_id, product#82]\n+- Relation [product#82,product_id#83] JDBCRelation(product) [numPartitions=1]\n"
     ]
    }
   ],
   "source": [
    "insert_from_df(df=tran_dim2, table=\"trans_dim\")\n",
    "insert_from_df(df=customer_dim, table=\"cust_dim\")\n",
    "insert_from_df(df=product_dim.select([\"prod_id\", \"product\"]), table=\"prod_dim\")\n",
    "insert_from_df(df=tran_prod_fact, table=\"trans_prod_fact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf07a3-122f-42e6-8e3c-6e435fe39b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
